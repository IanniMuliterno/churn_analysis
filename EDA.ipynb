{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the problem\n",
    "- Objective: Determine why and when customers are leaving.\n",
    "- Business Impact: Assess how churn impacts revenue and long-term growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew,kurtosis, pearsonr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>ses_rec</th>\n",
       "      <th>ses_rec_avg</th>\n",
       "      <th>ses_rec_sd</th>\n",
       "      <th>ses_rec_cv</th>\n",
       "      <th>user_rec</th>\n",
       "      <th>ses_n</th>\n",
       "      <th>ses_n_r</th>\n",
       "      <th>int_n</th>\n",
       "      <th>int_n_r</th>\n",
       "      <th>...</th>\n",
       "      <th>int_cat16_n</th>\n",
       "      <th>int_cat17_n</th>\n",
       "      <th>int_cat18_n</th>\n",
       "      <th>int_cat19_n</th>\n",
       "      <th>int_cat20_n</th>\n",
       "      <th>int_cat21_n</th>\n",
       "      <th>int_cat22_n</th>\n",
       "      <th>int_cat23_n</th>\n",
       "      <th>int_cat24_n</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.935800e+04</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "      <td>49358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.072986e+05</td>\n",
       "      <td>15.454840</td>\n",
       "      <td>11.231611</td>\n",
       "      <td>2.711961</td>\n",
       "      <td>-0.020100</td>\n",
       "      <td>33.822947</td>\n",
       "      <td>3.366445</td>\n",
       "      <td>0.172372</td>\n",
       "      <td>6.716277</td>\n",
       "      <td>1.720975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955792</td>\n",
       "      <td>0.773714</td>\n",
       "      <td>0.382977</td>\n",
       "      <td>0.732424</td>\n",
       "      <td>0.503343</td>\n",
       "      <td>0.447020</td>\n",
       "      <td>2.102577</td>\n",
       "      <td>0.038130</td>\n",
       "      <td>0.099579</td>\n",
       "      <td>0.885591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.072098e+05</td>\n",
       "      <td>9.184645</td>\n",
       "      <td>18.162743</td>\n",
       "      <td>6.583917</td>\n",
       "      <td>0.917701</td>\n",
       "      <td>25.237703</td>\n",
       "      <td>7.380573</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>38.528882</td>\n",
       "      <td>1.455885</td>\n",
       "      <td>...</td>\n",
       "      <td>6.086722</td>\n",
       "      <td>5.003517</td>\n",
       "      <td>4.569604</td>\n",
       "      <td>4.977989</td>\n",
       "      <td>3.259194</td>\n",
       "      <td>3.873684</td>\n",
       "      <td>16.273213</td>\n",
       "      <td>0.593681</td>\n",
       "      <td>1.135149</td>\n",
       "      <td>0.318311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.532920e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.100910e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.060355e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638646</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.407573e+06</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>11.525121</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5549.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>2282.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          visitorid       ses_rec   ses_rec_avg    ses_rec_sd    ses_rec_cv  \\\n",
       "count  4.935800e+04  49358.000000  49358.000000  49358.000000  49358.000000   \n",
       "mean   7.072986e+05     15.454840     11.231611      2.711961     -0.020100   \n",
       "std    4.072098e+05      9.184645     18.162743      6.583917      0.917701   \n",
       "min    3.700000e+01      0.000000      0.000000      0.000000     -1.000000   \n",
       "25%    3.532920e+05      7.000000      0.000000      0.000000     -1.000000   \n",
       "50%    7.100910e+05     16.000000      2.250000      0.000000      0.000000   \n",
       "75%    1.060355e+06     23.000000     14.250000      1.000000      0.638646   \n",
       "max    1.407573e+06     31.000000     99.000000     47.500000     11.525121   \n",
       "\n",
       "           user_rec         ses_n       ses_n_r         int_n       int_n_r  \\\n",
       "count  49358.000000  49358.000000  49358.000000  49358.000000  49358.000000   \n",
       "mean      33.822947      3.366445      0.172372      6.716277      1.720975   \n",
       "std       25.237703      7.380573      0.372614     38.528882      1.455885   \n",
       "min        0.000000      2.000000     -1.000000      2.000000      1.000000   \n",
       "25%       16.000000      2.000000      0.060606      2.000000      1.000000   \n",
       "50%       26.000000      2.000000      0.090909      3.000000      1.250000   \n",
       "75%       46.000000      3.000000      0.166667      6.000000      2.000000   \n",
       "max       99.000000    475.000000     18.000000   5549.000000     59.000000   \n",
       "\n",
       "       ...   int_cat16_n   int_cat17_n   int_cat18_n   int_cat19_n  \\\n",
       "count  ...  49358.000000  49358.000000  49358.000000  49358.000000   \n",
       "mean   ...      0.955792      0.773714      0.382977      0.732424   \n",
       "std    ...      6.086722      5.003517      4.569604      4.977989   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...    576.000000    445.000000    481.000000    564.000000   \n",
       "\n",
       "        int_cat20_n   int_cat21_n   int_cat22_n   int_cat23_n   int_cat24_n  \\\n",
       "count  49358.000000  49358.000000  49358.000000  49358.000000  49358.000000   \n",
       "mean       0.503343      0.447020      2.102577      0.038130      0.099579   \n",
       "std        3.259194      3.873684     16.273213      0.593681      1.135149   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      2.000000      0.000000      0.000000   \n",
       "max      317.000000    420.000000   2282.000000     54.000000    105.000000   \n",
       "\n",
       "       target_class  \n",
       "count  49358.000000  \n",
       "mean       0.885591  \n",
       "std        0.318311  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ecom-user-churn-data.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deal with duplicates, handle missing values and anomalies.\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis\n",
    "- For Skewness:\n",
    "    - A skewness close to 0 indicates a symmetrical distribution.\n",
    "    - A skewness greater than 1 or less than -1 indicates a highly skewed distribution.\n",
    "    - A skewness between -1 and -0.5 or between 0.5 and 1 indicates moderate skewness.\n",
    "- For Kurtosis:\n",
    "    - A kurtosis greater than 3 indicates a leptokurtic distribution. Traditional interpretations would subtract 3 (excess kurtosis), so a value greater than 0 in this excess kurtosis indicates more outliers than the normal distribution.\n",
    "    - A kurtosis less than 3 indicates a platykurtic distribution. With excess kurtosis (kurtosis - 3), a value less than 0 indicates fewer outliers. \n",
    "    \n",
    "These metrics are valuable for data preprocessing in machine learning. Highly skewed or kurtotic data may need transformation, such as logarithmic, square root, or box-cox transformation, to meet the assumptions of various statistical models and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#univariate analysis\n",
    "def univ_analysis(x):\n",
    "\n",
    "    \"\"\"\n",
    "    get quartiles, skewness, kurtosis and sparseness.\n",
    "    \"\"\"\n",
    "    distribution_stats = [np.quantile(x, [0,.25,.5,.75,1]), skew(x), kurtosis(x),round((1 - (np.count_nonzero(x)/len(x))),4)]\n",
    "    return distribution_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(univ_analysis).to_csv('df_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes a question, the combination of predictor variables can have stronger impact in the response variable even if some variables from that combination have no relevant correlation with the response variable? which are the main models where that situation can happen?\n",
    "\n",
    "Before getting into bivariate analysis, let's check the correlation and se which predictor variables we want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IM_py\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "pairs = list(product(df.columns, repeat = 2))\n",
    "corr_ls = []\n",
    "\n",
    "for c in pairs:\n",
    "    pair_corr, corr_pval = pearsonr(df[c[0]],df[c[1]])\n",
    "    corr_ls.append([c[0],c[1],pair_corr,corr_pval])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing WOE and IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iv(df,variable,target):\n",
    "\n",
    "    \n",
    "    lst = []\n",
    "    #Before analyzing the data, missing values within the feature of interest are filled with the string \"NULL\". This ensures that missing values are treated as a separate category during the IV calculation, allowing for the evaluation of their predictive power.\n",
    "    df[variable] = df[variable].fillna(\"NULL\")\n",
    "    #This block iterates through each unique value of the specified feature. For each unique value (val), it computes:\n",
    "    #The total number of occurrences of val.\n",
    "    #The count of occurrences where the target variable is 0 (\"churn\").\n",
    "    #The count of occurrences where the target variable is 1 (\"no churn\").\n",
    "    #These counts are appended to the list lst as a sublist, including the feature name and the value being analyzed.~\n",
    "\n",
    "\n",
    "    for i in range(df[variable].nunique()):\n",
    "\n",
    "        variable_val = df[variable].unique()[i]\n",
    "        total_ocur = len(df[(df[variable] == variable_val)])\n",
    "        total_churn = len(df[(df[variable] == variable_val) & (df[(df[target] == 0)])])\n",
    "        total_nochurn = len(df[(df[variable] == variable_val) & (df[(df[target] == 1)])])\n",
    "\n",
    "        lst.append([variable,variable_val,total_ocur,total_churn,total_nochurn])\n",
    "        \n",
    "    #Share: The proportion of observations for each unique value relative to the total number of observations.\n",
    "    #share churn: The proportion of the \"bad\" outcome for each unique value.\n",
    "    #Distribution Good Rate and Distribution Bad Rate: The distribution of good and bad rates across the unique values.\n",
    "    #WoE (Weight of Evidence): A measure of the predictive power of an independent variable in separating the classes.\n",
    "    woe_df = pd.DataFrame(data = lst, columns= ['feature','feature_val','total_ocur','total_churn','total_nochurn' ])\n",
    "\n",
    "    woe_df['share'] = woe_df['total_ocur']/woe_df['total_ocur'].sum()\n",
    "    woe_df['share_churn'] = woe_df['total_churn']/woe_df['total_ocur'].sum()\n",
    "    woe_df['distribution_churn'] = woe_df['total_churn']/woe_df['total_churn'].sum()\n",
    "    woe_df['distribution_nochurn'] = woe_df['total_nochurn']/woe_df['total_nochurn'].sum()\n",
    "    woe_df['WoE'] = np.log(woe_df['distribution_nochurn']/woe_df['distribution_churn'])\n",
    "    woe_df = woe_df.replace({'WoE':{np.inf: 0, -np.inf:0}})\n",
    "    # Calculates the Information Value for each unique value of the feature by multiplying the WoE by the \n",
    "    #difference in distributions of the good and bad rates. The IV is a summary measure that quantifies the\n",
    "    #predictive power of the independent variable.\n",
    "    print(woe_df)\n",
    "\n",
    "    woe_df['IV'] = woe_df['WoE']*(woe_df['distribution_nochurn'] - woe_df['distribution_churn'])\n",
    "\n",
    "    woe_df = woe_df.sort_values(by = ['feature','feature_val'],ascending = [True, True])\n",
    "\n",
    "    IV = woe_df['IV'].sum()\n",
    "\n",
    "    return IV,woe_df\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_iv(df,'ses_rec','target_class')\n",
    "#df['ses_rec'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>rho</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ses_rec</td>\n",
       "      <td>ses_rec_avg</td>\n",
       "      <td>-0.079104</td>\n",
       "      <td>2.404515e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ses_rec</td>\n",
       "      <td>ses_rec_sd</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>1.082075e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ses_rec</td>\n",
       "      <td>ses_rec_cv</td>\n",
       "      <td>-0.090615</td>\n",
       "      <td>1.707000e-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ses_rec</td>\n",
       "      <td>user_rec</td>\n",
       "      <td>0.232466</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ses_rec</td>\n",
       "      <td>ses_n</td>\n",
       "      <td>-0.069020</td>\n",
       "      <td>3.445606e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>target_class</td>\n",
       "      <td>int_cat20_n</td>\n",
       "      <td>-0.073814</td>\n",
       "      <td>1.353599e-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>target_class</td>\n",
       "      <td>int_cat21_n</td>\n",
       "      <td>-0.056880</td>\n",
       "      <td>1.164528e-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>target_class</td>\n",
       "      <td>int_cat22_n</td>\n",
       "      <td>-0.065256</td>\n",
       "      <td>1.005240e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>target_class</td>\n",
       "      <td>int_cat23_n</td>\n",
       "      <td>-0.033202</td>\n",
       "      <td>1.604395e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>target_class</td>\n",
       "      <td>int_cat24_n</td>\n",
       "      <td>-0.037214</td>\n",
       "      <td>1.335600e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              from           to       rho        pvalue\n",
       "51         ses_rec  ses_rec_avg -0.079104  2.404515e-69\n",
       "52         ses_rec   ses_rec_sd -0.079306  1.082075e-69\n",
       "53         ses_rec   ses_rec_cv -0.090615  1.707000e-90\n",
       "54         ses_rec     user_rec  0.232466  0.000000e+00\n",
       "55         ses_rec        ses_n -0.069020  3.445606e-53\n",
       "...            ...          ...       ...           ...\n",
       "2395  target_class  int_cat20_n -0.073814  1.353599e-60\n",
       "2396  target_class  int_cat21_n -0.056880  1.164528e-36\n",
       "2397  target_class  int_cat22_n -0.065256  1.005240e-47\n",
       "2398  target_class  int_cat23_n -0.033202  1.604395e-13\n",
       "2399  target_class  int_cat24_n -0.037214  1.335600e-16\n",
       "\n",
       "[1334 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = pd.DataFrame(data= corr_ls,columns=['from','to','rho','pvalue'])\n",
    "corr_df[(abs(corr_df['rho']) > .8 ) & (corr_df['from'] != corr_df['to'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5647"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['target_class'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(n/2) - 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
